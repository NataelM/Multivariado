{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02808748-0308-4480-a303-f16d07d23fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML\n",
    "import warnings\n",
    "from scipy import stats\n",
    "from scipy.stats import skew, levene, ttest_ind, ks_2samp, chi2_contingency\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import nestle\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "\n",
    "from math import exp\n",
    "\n",
    "pd.set_option('max_colwidth',100)\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc7a097-fc2a-44aa-b1aa-43723a04808d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gama_vector():\n",
    "    f_1=stats.gamma(a=2,scale=4)\n",
    "    f_2=stats.gamma(a=1,scale=4)\n",
    "    x_1=f_1.rvs(size=1)\n",
    "    x_2=f_2.rvs(size=1)*exp(x_1)\n",
    "    return[x_1,x_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5643bfa-d612-4e24-bd92-fe5444107ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_vector():\n",
    "    u_1=np.random.uniform(0,1)\n",
    "    u_2=np.random.uniform(0,1)\n",
    "    z_1=np.sqrt(-2*np.log(u_1))*math.cos(2*math.pi*u_2)\n",
    "    z_2=np.sqrt(-2*np.log(u_1))*math.sin(2*math.pi*u_2)\n",
    "    return[z_1,z_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32f0a57-027b-424a-bef2-b21c54d31c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_vector():\n",
    "    X=u+np.dot(np.dot(gamma_s,lamdas2_s),np.array(z_vector()).T)\n",
    "    return[X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cafd7fb6-3f0d-42c6-9ca2-0607116a3f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStdDataMatrix(data:pd.DataFrame, columns:list, keys:list):\n",
    "    '''\n",
    "    Entendemos porestandarización a restar la media \n",
    "    y dividir entre la varianza\n",
    "    data: df \n",
    "    columns: columnas a estandarizar en una lista o iterable\n",
    "    keys: columnad que no voy a centrar/estandarizar es una cadena dentro de una lista\n",
    "    \n",
    "    regresa un df con las columnas estandarizada\n",
    "    '''\n",
    "    dataframePD = data.copy(deep = True)\n",
    "    \n",
    "    #vecctor de medias en diccionario\n",
    "    meanVector = dataframePD.mean().to_dict()\n",
    "    \n",
    "    #vector de desviaciones estandar en diccionario\n",
    "    stdVector = dataframePD.std().to_dict()\n",
    "    \n",
    "    # por columna estandarizar \n",
    "    for col in columns:\n",
    "        dataframePD['std_'+col] = (dataframePD[col]-meanVector[col])/stdVector[col]\n",
    "    return dataframePD[keys+['std_'+col for col in columns]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62e1fde7-774e-4844-ad7d-1034966c724f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ellipsoid_3d(ell, ax):\n",
    "    \"\"\"Plot the 3-d Ellipsoid ell on the Axes3D ax.\"\"\"\n",
    "\n",
    "    # points on unit sphere\n",
    "    u = np.linspace(0.0, 2.0 * np.pi, 100)\n",
    "    v = np.linspace(0.0, np.pi, 100)\n",
    "    z = np.outer(np.cos(u), np.sin(v))\n",
    "    y = np.outer(np.sin(u), np.sin(v))\n",
    "    x = np.outer(np.ones_like(u), np.cos(v))\n",
    "\n",
    "    # transform points to ellipsoid\n",
    "    for i in range(len(x)):\n",
    "        for j in range(len(x)):\n",
    "            x[i,j], y[i,j], z[i,j] = (ell.ctr + np.dot(ell.axes,\n",
    "                                                      [x[i,j],y[i,j],z[i,j]])).reshape(3, 1)\n",
    "\n",
    "    ax.plot_wireframe(x, y, z,  rstride=4, cstride=4, color='#2980b9', alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27db70ca-410e-4f35-ab65-21681b60153f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anls_num(df, columna_num:str, target:str): \n",
    "    ''' \n",
    "    df: dataframe \n",
    "    columna num: columna de tipo numerica, float o entera \n",
    "     \n",
    "    Esta función realiza una prueba de hipotesis sobre igualdad en media  \n",
    "    vía una prueba t de student sobre *columna_num* cuyas poblaciones a medir \n",
    "    están dadas por la variable \"target\". \n",
    "    Se hace un análisis BOxplot y distribución. \n",
    "    ''' \n",
    "    #se asume que el target es binario \n",
    "    ceros = df[df[target] == False][columna_num] \n",
    "    unos  = df[df[target] == True][columna_num] \n",
    "     \n",
    "    print(f' ANALISIS DE {columna_num} '.center(100, '*')) \n",
    "    ########################### VARIANZAS ############################## \n",
    "    ################ coeficiente de asimetría ######################## \n",
    "    asim = '' \n",
    "    if skew(df[columna_num]) != 0: \n",
    "        asim = 'median' \n",
    "         \n",
    "        ############# HIPOTESIS DE VARIANZAS IGUALES PRUEBA DE LEVENE ############# \n",
    "        ################ p_value < 0.05 se rechaza H_0 \n",
    "        # H_0 varianzas iguales \n",
    "        _, p_valor_var = levene(ceros, unos, center = asim ) \n",
    "        if p_valor_var < 0.05: \n",
    "            print(f'con un p_value de {p_valor_var} se rechaza que las varianzas sean iguales') \n",
    "        else: \n",
    "            print(f'con un p_value de {p_valor_var} se acepta que las varianzas sean iguales') \n",
    "         \n",
    "    else: #si la asimetría es igual a cero \n",
    "        asim = 'mean' \n",
    "         \n",
    "        ############# HIPOTESIS DE VARIANZAS IGUALES PRUEBA DE LEVENE ############# \n",
    "        ################ p_value < 0.05 se rechaza H_0 \n",
    "        # H_0 varianzas iguales \n",
    "        _, p_valor_var = levene(ceros, unos, center = asim ) \n",
    "        if p_valor_var < 0.05: \n",
    "            print(f'con un p_value de {p_valor_var} se rechaza que las varianzas sean iguales') \n",
    "        else: \n",
    "            print(f'con un p_value de {p_valor_var} se acepta que las varianzas sean iguales') \n",
    "             \n",
    "    print(f'Varianza(False) = { round((ceros).var(), 3) }') \n",
    "    print(f'Varianza(True) = { round((unos).var(), 3) }') \n",
    "     \n",
    "    ######################### MEADIAS ############################################### \n",
    "    ####### HIPOTESISIS DE MEDIAS IGUALES ########### \n",
    "    #>0.05 no se rechaza la prueba t (H_0) H_0: las muestras son iguales en media \n",
    "    if p_valor_var < 0.05: # si las varianzas son distintas \n",
    "        _, p_valor = ttest_ind(ceros, unos, equal_var = False) \n",
    "    else: # si las varianzas son iguales \n",
    "        _, p_valor = ttest_ind(ceros, unos, equal_var = True) \n",
    "     \n",
    "    if p_valor < 0.05: \n",
    "        print(f'con un p_value de {p_valor} no se acepta que las medias sean iguales') \n",
    "    else: \n",
    "        print(f'''con un p_value de {p_valor} no se rechaza que las medias sean iguales \n",
    "               es decir, no hay evidencia estadistica suficiente para rechazar que las medias \n",
    "               son iguales \n",
    "               ''') \n",
    "    print(f'mean(False) = { round((ceros).mean(), 3) }') \n",
    "    print(f'mean(True) = { round((unos).mean(), 3) }') \n",
    "     \n",
    "    ################################# DISTRIBUCIONES #################################### \n",
    "    # H_0: las distribuciones son iguales \n",
    "    # p_value < 0.05 se rechaza H_0 \n",
    "    if ks_2samp(unos, ceros).pvalue < 0.05: \n",
    "        print(f'Con un p_value de {ks_2samp(ceros, unos).pvalue} se rechaza H_0, es decir, las distribuciones NO son iguales') \n",
    "    else: \n",
    "        print(f'Con un p_value de {ks_2samp(ceros, unos).pvalue} NO se rechaza H_0,es decir, las distribuciones son iguales') \n",
    "     \n",
    "    fig = px.violin(df,  \n",
    "                y = columna_num,  \n",
    "                x = target,  \n",
    "                color = target,  \n",
    "                box = True,  \n",
    "                points = \"all\", \n",
    "                hover_data = df.columns) \n",
    "    fig.show();\n",
    "    \n",
    "    \n",
    "def modas(df:pd.DataFrame, col_1:str, col_2:str): \n",
    "    ''' \n",
    "    df: dataframe \n",
    "    col_1: es el nombre de la columna apara la tabla de contingencias \n",
    "    col_2: (T)arget es el nombre de la columna con la que se hacen las contingencias \n",
    "     \n",
    "     \n",
    "    Esta columna recibe un df, dos columanas \n",
    "    y realiza una tabla de contingencias, \n",
    "    y compara si la moda es la misma segun la  \n",
    "    población objetivo (col_2 se sugiere como la target) \n",
    "    ''' \n",
    "    ############# TABLA DE CONTINGENCIAS \n",
    "    data_crosstab  = pd.crosstab(df[col_1], \n",
    "                            df[col_2],  \n",
    "                            margins = False) \n",
    "    ######### SE ASUME QUE EL TARGET ES BINARIO y que está en las columnas \n",
    "    moda_0 =  data_crosstab[False].argmax() # posición donde se encuentra la max frec \n",
    "    moda_1 =  data_crosstab[True].argmax() # posición donde se encuentra la max frec \n",
    "     \n",
    "    # los indices en la tabla cruzada son la característica a revisar \n",
    "    moda_name_0 = data_crosstab[False].index[moda_0] #nombre de la posición maxima \n",
    "    moda_name_1 = data_crosstab[True].index[moda_1] #nombre de la posición maxima \n",
    "     \n",
    "    if moda_name_0 == moda_name_1: \n",
    "        print('las modas son iguales') \n",
    "        print(moda_name_0, '=', moda_name_1) \n",
    "    else: \n",
    "        print('las modas son distintas') \n",
    "        print(moda_name_0, '!=', moda_name_1) \n",
    "         \n",
    "    return data_crosstab\n",
    "\n",
    "def corr_cat(df, col:str, target:str): \n",
    "    ''' \n",
    "    df: pandas data frame \n",
    "    col: str nombre de la columna con la cual queremos checar la correlacion \n",
    "    target: str nombre de la variable target \n",
    "     \n",
    "    P[(T)arget | (C)lase]      P[(T)arget and (C)lase]     \n",
    "    --------------------- = -------------------------------- \n",
    "        P[(T)arget]            P[(T)arget] *  P[(C)lase] \n",
    "         \n",
    "    lo anterior se resume a:  \n",
    "    (la frecuencia de la clase \"i\" entre el total) entre \n",
    "    [ \n",
    "    (la frecuencias de toda la clase entre el total) multiplicado por \n",
    "    (la frecuencia del target = 1 (o cero) entre el total)    \n",
    "    ] \n",
    "    indices > 1.5 se considerarán como mayormente correlacionados \n",
    "    ''' \n",
    "    data_crosstab  = pd.crosstab(df[target], # por estructura la primera entrada de la crosstab es el target \n",
    "                            df[col],  \n",
    "                            margins = True) # sí se necesiatn los totales \n",
    "     \n",
    "    #diccionario donde guardaremos las correlaciones \n",
    "    lista = [] \n",
    "     \n",
    "    for i in data_crosstab.columns: \n",
    "        if i == 'All': \n",
    "            continue \n",
    "        else: \n",
    "            # probabilidad de que la categoría sea \"i\" y además tenga etiqueta 1 \n",
    "            p_t_y_c_i = data_crosstab[i][True] / data_crosstab['All']['All'] \n",
    "            #probabilidad de que ocurra la categoría \"i\" \n",
    "            p_c_i     = data_crosstab[i]['All'] / data_crosstab['All']['All'] \n",
    "            #probabilidad de que ocurra la etiqueta 1 \n",
    "            p_t_1     = data_crosstab['All'][True] / data_crosstab['All']['All'] \n",
    "             \n",
    "            #KPI de correlación \n",
    "            coor_c_i = p_t_y_c_i / (p_c_i*p_t_1) \n",
    "             \n",
    "            lista.append([col, i, coor_c_i]) \n",
    "             \n",
    "    return pd.DataFrame(lista, columns = ['variable', 'nivel', 'valor'])#.sort_values('valor', ascending = False).head(430)\n",
    "\n",
    "def anls_cat(df, col_cat:str, target:str, umbral:float): \n",
    "    ''' \n",
    "    -Esta función análiza si las modas de poblaciones son iguales \n",
    "    (haciendo partición por la variable target), \n",
    "     \n",
    "    -Además nos dice si la columna ctegorica está relacionada con el target \n",
    "    mediante una prueba chi cuadrada \n",
    "     \n",
    "    -además, por variable categorica nos indica el numero de categorias que están  \n",
    "    correlacionadas con el target = 1 con cierto \"umbral\" \n",
    "    ''' \n",
    "    print(f' ANÁLISIS DE {col_cat} '.center(100, '*')) \n",
    "    ################## Comparación de modas \n",
    "    cros_tab_i = modas(df, col_cat, target) \n",
    "     \n",
    "    ################## Prueba CHI cuadradda \n",
    "    #la hipótesis nula (H0), que afirma que las variables no tienen relación.  \n",
    "    #la hipótesis alternativa (H1) es que existe un vínculo significativo \n",
    "    #p_value < 0.05 se rechaza H0  \n",
    "    _, p, _, _ = chi2_contingency(cros_tab_i.transpose()) \n",
    "    if p < 0.05: \n",
    "        print(f'\\nCon un p_value del {p} se dice que las variables están correlacionadas') \n",
    "    else: \n",
    "        print(f'\\nCon un p_value del {p} se dice que las variables *NO* están correlacionadas') \n",
    "         \n",
    "    ################# numero de categorias correlacionadas con la etiqueta 1 \n",
    "    df_corr_i = corr_cat(df, col_cat, target) \n",
    "    num_cat_corr = len(df_corr_i[df_corr_i['valor'] >= umbral]) \n",
    "    print(f'\\nPara la variable {col_cat} hay {num_cat_corr} categorias que \"pesan\" en la etiqueta 1\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833cfbed-7f80-41b2-a10f-b77ae9912218",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
